"""
åœ¨ Kaggle ä¸­å¿«é€Ÿè½¬æ¢å·²è®­ç»ƒçš„æ¨¡å‹æ–‡ä»¶
å°† CatEmbeddingModel çš„ state_dict è½¬æ¢ä¸ºåç«¯å¯ç”¨çš„æ ¼å¼
"""
import torch
import os

def convert_kaggle_model(input_path="/kaggle/working/cat_embedding_triplet.pth", 
                         output_path="/kaggle/working/cat_resnet18.pth"):
    """
    è½¬æ¢ Kaggle ä¸­çš„æ¨¡å‹æ–‡ä»¶æ ¼å¼
    
    Args:
        input_path: è¾“å…¥çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ /kaggle/working/cat_embedding_triplet.pthï¼‰
        output_path: è¾“å‡ºçš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ /kaggle/working/cat_resnet18.pthï¼‰
    """
    print("=" * 60)
    print("ğŸ”„ æ¨¡å‹æ ¼å¼è½¬æ¢å·¥å…·")
    print("=" * 60)
    print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {output_path}\n")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_path}")
        print("\nğŸ’¡ æç¤º: è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä¿®æ”¹è„šæœ¬ä¸­çš„ input_path å‚æ•°")
        return None
    
    try:
        # åŠ è½½åŸå§‹æ¨¡å‹
        print("ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        state_dict = torch.load(input_path, map_location='cpu')
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹ï¼ŒåŒ…å« {len(state_dict)} ä¸ªé”®")
        
        # æ£€æŸ¥é”®åæ ¼å¼
        sample_keys = list(state_dict.keys())[:5]
        print(f"\nğŸ“‹ å‰5ä¸ªé”®åç¤ºä¾‹:")
        for i, key in enumerate(sample_keys, 1):
            print(f"   {i}. {key}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦è½¬æ¢
        needs_conversion = any(key.startswith('backbone.') for key in state_dict.keys())
        
        if not needs_conversion:
            print("\nâš ï¸  æ¨¡å‹é”®åå·²ç»æ˜¯æ­£ç¡®æ ¼å¼ï¼ˆæ²¡æœ‰ 'backbone.' å‰ç¼€ï¼‰")
            print("   ä½†ä¸ºäº†ç¡®ä¿å…¼å®¹æ€§ï¼Œä»ç„¶ä¼šå¤„ç†...")
        
        # è½¬æ¢ï¼šå»æ‰ "backbone." å‰ç¼€
        print("\nğŸ”„ æ­£åœ¨è½¬æ¢é”®å...")
        converted_state = {}
        skipped_keys = []
        
        for key, value in state_dict.items():
            if key.startswith('backbone.'):
                # å»æ‰ "backbone." å‰ç¼€
                new_key = key[len('backbone.'):]
                converted_state[new_key] = value
            elif key == 'backbone':
                # å¦‚æœæ•´ä¸ªæ¨¡å‹è¢«ä¿å­˜ä¸ºä¸€ä¸ª backbone å¯¹è±¡
                print("âš ï¸  æ£€æµ‹åˆ°æ•´ä¸ª backbone å¯¹è±¡ï¼Œå°è¯•æå–...")
                if hasattr(value, 'state_dict'):
                    backbone_dict = value.state_dict()
                    converted_state.update(backbone_dict)
            else:
                # å…¶ä»–é”®ï¼ˆå¯èƒ½æ˜¯ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰ï¼Œè·³è¿‡
                skipped_keys.append(key)
        
        if skipped_keys:
            print(f"\nâš ï¸  å·²è·³è¿‡ {len(skipped_keys)} ä¸ªé backbone é”®")
            if len(skipped_keys) <= 5:
                for key in skipped_keys:
                    print(f"   - {key}")
        
        print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
        print(f"   åŸå§‹é”®æ•°: {len(state_dict)}")
        print(f"   è½¬æ¢åé”®æ•°: {len(converted_state)}")
        
        # ä¿å­˜è½¬æ¢åçš„æ¨¡å‹
        print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°: {output_path}")
        torch.save(converted_state, output_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜ï¼")
        
        # éªŒè¯æ–‡ä»¶å¤§å°
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        
        # éªŒè¯ï¼šå°è¯•åŠ è½½åˆ° ResNet18 çœ‹çœ‹æ˜¯å¦åŒ¹é…
        print("\nğŸ” æ­£åœ¨éªŒè¯æ¨¡å‹å…¼å®¹æ€§...")
        try:
            from torchvision.models import resnet18, ResNet18_Weights
            test_model = resnet18(weights=ResNet18_Weights.DEFAULT)
            test_model.fc = torch.nn.Identity()
            
            # å°è¯•åŠ è½½ï¼ˆstrict=False å…è®¸éƒ¨åˆ†åŒ¹é…ï¼‰
            missing_keys, unexpected_keys = test_model.load_state_dict(converted_state, strict=False)
            
            if len(missing_keys) == 0 and len(unexpected_keys) == 0:
                print("âœ… å®Œç¾åŒ¹é…ï¼æ‰€æœ‰é”®éƒ½èƒ½æ­£ç¡®åŠ è½½")
            else:
                if missing_keys:
                    print(f"âš ï¸  ç¼ºå°‘çš„é”® ({len(missing_keys)} ä¸ª): {missing_keys[:3]}...")
                if unexpected_keys:
                    print(f"âš ï¸  å¤šä½™çš„é”® ({len(unexpected_keys)} ä¸ª): {unexpected_keys[:3]}...")
                print("   ğŸ’¡ ä½¿ç”¨ strict=False åº”è¯¥ä»ç„¶å¯ä»¥å·¥ä½œ")
            
            print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡ï¼Œå¯ä»¥ç”¨äºåç«¯ï¼")
            
        except Exception as e:
            print(f"âš ï¸  éªŒè¯æ—¶å‡ºç°è­¦å‘Š: {e}")
            print("   ä½†æ¨¡å‹æ–‡ä»¶å·²ä¿å­˜ï¼Œä½ å¯ä»¥æ‰‹åŠ¨æµ‹è¯•")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ è½¬æ¢å®Œæˆï¼")
        print(f"ğŸ“¥ å¯ä»¥ä» Kaggle ä¸‹è½½: {output_path}")
        print("=" * 60)
        
        return output_path
        
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {input_path}")
        return None
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # åœ¨ Kaggle Notebook ä¸­ç›´æ¥è¿è¡Œæ­¤è„šæœ¬
    # é»˜è®¤è½¬æ¢ /kaggle/working/cat_embedding_triplet.pth
    
    # æ–¹å¼1: ä½¿ç”¨é»˜è®¤è·¯å¾„
    convert_kaggle_model()
    
    # æ–¹å¼2: è‡ªå®šä¹‰è·¯å¾„ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹ï¼‰
    # convert_kaggle_model(
    #     input_path="/kaggle/working/your_model.pth",
    #     output_path="/kaggle/working/cat_resnet18.pth"
    # )

