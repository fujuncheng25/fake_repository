import os
import random
import shutil
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, transforms
from torchvision.models import resnet18, ResNet18_Weights
from tqdm import tqdm

# 1) è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# 2) é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

# 3) æ•°æ®é›†ï¼ˆImageFolder: æ¯ä¸ªçŒ«ä¸ªä½“ä¸€ä¸ªå­ç›®å½•ï¼‰
data_dir = "/kaggle/input/cat-individuals/cat_individuals_dataset"  # æ”¹æˆä½ çš„è·¯å¾„
dataset = datasets.ImageFolder(data_dir, transform=transform)
num_cats = len(dataset.classes)
print("çŒ«ä¸ªä½“æ•°é‡:", num_cats)

# 4) æ¨¡å‹ï¼šResNet18 + Identity() -> 512ç»´åµŒå…¥ï¼ˆä¸åç«¯å®Œå…¨ä¸€è‡´ï¼‰
class CatEmbeddingModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)
        self.backbone.fc = nn.Identity()  # ç›´æ¥è¾“å‡º [B, 512]

    def forward(self, x):
        x = self.backbone(x)              # [B, 512]
        return nn.functional.normalize(x, p=2, dim=1)

model = CatEmbeddingModel().to(device)

# 5) Triplet é‡‡æ ·å™¨ï¼ˆåŒç±»æ­£æ ·ï¼Œæœ¬ç±»å¤–è´Ÿæ ·ï¼‰
class TripletDataset(Dataset):
    def __init__(self, base_dataset):
        self.ds = base_dataset
        self.targets = base_dataset.targets
        self.class_to_indices = {}
        for idx, y in enumerate(self.targets):
            self.class_to_indices.setdefault(y, []).append(idx)
        # è¿‡æ»¤åªæœ‰1å¼ å›¾çš„ç±»ï¼Œé¿å…å–æ­£æ ·å¤±è´¥
        self.valid_classes = [c for c, idxs in self.class_to_indices.items() if len(idxs) >= 2]
        self.other_classes = {}
        all_classes = list(self.class_to_indices.keys())
        for c in all_classes:
            self.other_classes[c] = [x for x in all_classes if x != c and len(self.class_to_indices[x]) > 0]

    def __len__(self):
        return len(self.ds)

    def __getitem__(self, index):
        anchor_img, anchor_label = self.ds[index]
        # é€‰æ­£æ ·ï¼ˆåŒç±»ä¸åŒå›¾ï¼‰
        pos_choices = self.class_to_indices.get(anchor_label, [])
        if len(pos_choices) < 2:
            # è‹¥è¯¥ç±»ä¸è¶³ä¸¤å¼ ï¼Œéšæœºæ¢ä¸€ä¸ªæœ‰æ•ˆç±»ä½œä¸ºé”šç‚¹
            anchor_label = random.choice(self.valid_classes)
            index = random.choice(self.class_to_indices[anchor_label])
            anchor_img, _ = self.ds[index]
            pos_choices = self.class_to_indices[anchor_label]
        pos_index = index
        while pos_index == index:
            pos_index = random.choice(pos_choices)
        positive_img, _ = self.ds[pos_index]
        # è´Ÿæ ·ï¼ˆä¸åŒç±»ï¼‰
        neg_label = random.choice(self.other_classes[anchor_label])
        neg_index = random.choice(self.class_to_indices[neg_label])
        negative_img, _ = self.ds[neg_index]
        return anchor_img, positive_img, negative_img

triplet_ds = TripletDataset(dataset)
loader = DataLoader(triplet_ds, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)

# 6) æŸå¤±ä¸ä¼˜åŒ–
criterion = nn.TripletMarginLoss(margin=1.0, p=2)
optimizer = optim.Adam(model.parameters(), lr=5e-4)
scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())

# 7) è®­ç»ƒ
epochs = 5
for epoch in range(epochs):
    model.train()
    running = 0.0
    bar = tqdm(loader, desc=f"Epoch {epoch+1}/{epochs}", leave=False)
    for anchor, positive, negative in bar:
        anchor = anchor.to(device, non_blocking=True)
        positive = positive.to(device, non_blocking=True)
        negative = negative.to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)
        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
            emb_a = model(anchor)
            emb_p = model(positive)
            emb_n = model(negative)
            loss = criterion(emb_a, emb_p, emb_n)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        running += loss.item()
        bar.set_postfix(loss=f"{loss.item():.4f}")

    print(f"Epoch {epoch+1}, Avg Loss: {running/len(loader):.4f}")

# 8) ä¿å­˜ï¼ˆå…³é”®ä¿®å¤ï¼šåªä¿å­˜ backbone çš„ state_dictï¼Œé”®åä¸åç«¯å®Œå…¨åŒ¹é…ï¼‰
save_name = "cat_resnet18.pth"
kaggle_path = "/kaggle/working/cat_resnet18.pth"

# âš ï¸ é‡è¦ï¼šåç«¯æœŸæœ›ç›´æ¥æ˜¯ ResNet18 çš„ state_dictï¼Œä¸æ˜¯ CatEmbeddingModel çš„
# æ‰€ä»¥åªä¿å­˜ backbone çš„æƒé‡ï¼Œå»æ‰ "backbone." å‰ç¼€
print("æ­£åœ¨ä¿å­˜æ¨¡å‹...")
backbone_state = model.backbone.state_dict()
torch.save(backbone_state, kaggle_path)
print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {kaggle_path}")

# åŒæ—¶ä¿å­˜åˆ°å½“å‰ç›®å½•ï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ°æµ‹è¯•ï¼‰
try:
    torch.save(backbone_state, save_name)
    print(f"âœ… åŒæ—¶ä¿å­˜åˆ°: {save_name}")
except Exception as e:
    print(f"âš ï¸  æœ¬åœ°ä¿å­˜å¤±è´¥ï¼ˆä¸å½±å“ Kaggle ä½¿ç”¨ï¼‰: {e}")

print(f"\nğŸ‰ æ¨¡å‹ä¿å­˜å®Œæˆï¼å¯ä»¥ç›´æ¥ä» Kaggle ä¸‹è½½: {kaggle_path}")

